import pickle
import numpy as np
import faiss
import torch
import textdistance

from transformers import RobertaTokenizer, RobertaModel

from IR.bert_whitening import sents_to_vecs, transform_and_normalize,normalize

tokenizer = RobertaTokenizer.from_pretrained("D:\\codebert-base")
model = RobertaModel.from_pretrained("D:\\codebert-base")
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(DEVICE)

#计算词汇相似度---通过编辑距离计算
def sim_edit(s1,s2):
    # score= Levenshtein.seqratio(s1, s2)    #计算两个字符串序列的相似率
    # score=Levenshtein.distance(s1,s2)    #计算两个字符串的绝对距离
    # sim=1-score/max(len(s1),len(s2))
    # print("编辑距离的值负数：",sim)
    score=textdistance.levenshtein.normalized_similarity(s1,s2)
    sim=score
    return sim


class Retrieval(object):
    def __init__(self, dim, whitening_file, kernel_file, bias_file, train_code_list, train_nl_list):
        f = open(whitening_file, 'rb')
        self.bert_vec = pickle.load(f)
        f.close()
        f = open(kernel_file, 'rb')
        self.kernel = pickle.load(f)
        f.close()
        f = open(bias_file, 'rb')
        self.bias = pickle.load(f)
        f.close()

        self.dim = dim
        self.train_code_list, self.train_nl_list = train_code_list, train_nl_list
        self.id2text = None
        self.vecs = None
        self.ids = None
        self.index = None

    def encode_file(self):
        all_texts = []
        all_ids = []
        all_vecs = []
        for i in range(len(self.train_code_list)):
            all_texts.append(self.train_code_list[i])
            all_ids.append(i)
            all_vecs.append(self.bert_vec[i].reshape(1,-1))
        all_vecs = np.concatenate(all_vecs, 0)
        id2text = {idx: text for idx, text in zip(all_ids, all_texts)}
        self.id2text = id2text
        self.vecs = np.array(all_vecs, dtype="float32")
        self.ids = np.array(all_ids, dtype="int64")

    def build_index(self, n_list):
        quant = faiss.IndexFlatIP(self.dim) #这种索引方式需要构建量化器
        index = faiss.IndexIVFFlat(quant, self.dim, min(n_list, self.vecs.shape[0]))
        index.train(self.vecs)
        index.add_with_ids(self.vecs, self.ids)
        self.index = index

    def single_query(self, code, topK):
        body = sents_to_vecs([code], tokenizer, model, ir=True)    #转换成向量,body的shape[1,768]
        body = transform_and_normalize(body, self.kernel, self.bias)  #body的shape[1,256]
        vec = body[[0]].reshape(1, -1).astype('float32')  # body的shape[1,256]
        #不使用whitening操作使用下面两行代码
        # body = normalize(body)  #body的shape[1,768]
        # vec = body.reshape(1, -1).astype('float32')  #body的shape[1,768]
        _, sim_idx = self.index.search(vec, topK)   #faiss库执行搜索
        sim_idx = sim_idx[0].tolist()
        max_score = 0
        max_idx = 0
        code_score_list = []
        for j in sim_idx:
            code_score=sim_edit(self.train_code_list[j].split(), code.split())         #通过编辑距离计算相似度
            code_score_list.append(code_score)
        for i in range(len(sim_idx)):
            code_score = code_score_list[i]
            score = code_score
            if score > max_score:
                max_score = score
                max_idx = sim_idx[i]
        return self.train_code_list[max_idx], self.train_nl_list[max_idx]
